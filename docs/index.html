<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SAE Feature Analysis</title>
    <link rel="stylesheet" href="assets/css/style.css">
    
    <!-- MathJax for LaTeX math rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['\\(', '\\)']],
                displayMath: [['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            }
        };
    </script>
    
    <style>
        /* Feature info 2x2 grid styling */
        .feature-info {
            margin-bottom: 1rem;
        }
        
        .info-row {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 0.5rem;
            gap: 1rem;
        }
        
        .info-left {
            flex: 0 0 auto;
        }
        
        .info-right {
            flex: 1;
            text-align: right;
            font-size: 0.75rem;
            font-family: monospace;
            color: #6c757d;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
        }
        
        .config-label {
            font-weight: bold;
            color: #6f42c1;
            margin-right: 0.5rem;
        }
        
        /* Ensure feature select and activation text are same size */
        .feature-title-select {
            font-size: 1rem;
            font-weight: bold;
        }
        
        .info-left p {
            margin: 0;
            font-size: 1rem;
        }
        
        /* Make feature viewer container relative for absolute positioning */
        .feature-viewer {
            position: relative;
        }
        
        /* Section navigation styling */
        .section-nav {
            background-color: transparent;
            padding: 0.5rem 0;
            margin: 0 0 1rem 0;
            font-size: 0.9rem;
        }
        
        .section-nav a {
            color: #6f42c1;
            text-decoration: none;
            font-size: 1.2rem;
        }
        
        .section-nav a:hover {
            text-decoration: underline;
        }

        .h3 {
            font-size: 2.3rem;
            color: #7b7b7b;
            margin-bottom: 1.5rem;
        }

        .h4 {
            font-size: 1.5rem;
            color: hsl(0, 0%, 46%);
            margin-bottom: 1.5rem;
        }
        
        /* Remove thin lines from subsubsections */
        .section-content-header {
            border-bottom: none !important;
        }
    </style>
</head>
<body>
    <main>
        <div class="container">
            <div class="tab-nav">
                <button class="tab-button active" id="about-tab" data-tab="about">About</button>
                <button class="tab-button" id="demo-tab" data-tab="demo">Explore Features</button>
            </div>

            <div id="about-content" class="tab-content active">
                <div class="about-content">
                    <div style="width: 100vw; margin-left: calc(-50vw + 50%); padding: 4rem 0; margin-bottom: 3rem;">
                        <div style="max-width: 1200px; margin: 0 auto; padding: 0 2rem;">
                            <h1 style="text-align: center; font-size: 3rem; font-weight: 700; color: #333; margin-bottom: 1rem;">
                                Interpretability for Neural TSP Solvers
                            </h1>
                            <p style="text-align: center; font-size: 1.2rem; color: #666; margin-bottom: 3rem; max-width: 800px; margin-left: auto; margin-right: auto;">
                                Investigating the latent space of a neural TSP solver using sparse autoencoders and linear probes.
                            </p>
                            
                            <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 2rem; margin-top: 3rem;">
                                <!-- TSP Solver Panel -->
                                <div style="background: white; border-radius: 12px; padding: 2rem; box-shadow: 0 4px 12px rgba(0,0,0,0.1); text-align: center; cursor: pointer; transition: transform 0.2s ease;" onclick="document.getElementById('tsp-solver').scrollIntoView()">
                                    <div style="width: 100%; height: 300px; background: #f8f9fa; border-radius: 8px; margin-bottom: 1.5rem; display: flex; align-items: center; justify-content: center; overflow: hidden;">
                                        <img src="solution_demo.png" alt="TSP Solution Demo" style="width: 100%; height: 100%; object-fit: cover; border-radius: 8px;">
                                    </div>
                                    <h3 style="color: #000000; margin-bottom: 1rem; font-size: 1.5rem;">Neural TSP Solver</h3>
                                </div>
                                
                                <!-- Sparse Autoencoder Panel -->
                                <div style="background: white; border-radius: 12px; padding: 2rem; box-shadow: 0 4px 12px rgba(0,0,0,0.1); text-align: center; cursor: pointer; transition: transform 0.2s ease;" onclick="document.getElementById('sparse-autoencoder').scrollIntoView()">
                                    <div style="width: 100%; height: 300px; background: #f8f9fa; border-radius: 8px; margin-bottom: 1.5rem; display: flex; align-items: center; justify-content: center; overflow: hidden;">
                                        <img src="sae_demo.png" alt="SAE Demo" style="width: 100%; height: 100%; object-fit: cover; border-radius: 8px;">
                                    </div>
                                    <h3 style="color: #000000; margin-bottom: 1rem; font-size: 1.5rem;">Sparse Autoencoder</h3>
                                </div>
                                
                                <!-- Feature Analysis Panel -->
                                <div style="background: white; border-radius: 12px; padding: 2rem; box-shadow: 0 4px 12px rgba(0,0,0,0.1); text-align: center; cursor: pointer; transition: transform 0.2s ease;" onclick="document.getElementById('feature-analysis').scrollIntoView()">
                                    <div style="width: 100%; height: 300px; background: #f8f9fa; border-radius: 8px; margin-bottom: 1.5rem; display: flex; align-items: center; justify-content: center; overflow: hidden;">
                                        <img src="feature_demo.png" alt="Feature Analysis Demo" style="width: 100%; height: 100%; object-fit: cover; border-radius: 8px;">
                                    </div>
                                    <h3 style="color: #000000; margin-bottom: 1rem; font-size: 1.5rem;">Feature Analysis</h3>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <h2>Introduction</h2>
                    <div style='max-width: 800px; margin: 0 auto; line-height: 1.6; color: #000000;'>
                        <p>Sparse coding has garnered interest in the AI interpretability community for discovering features and circuits within the latent space of neural networks. While most of this interpretability work has focused on language models, the same techniques can be applied to other modalities. We are interested in applying these techniques on OR-solver models, starting with the TSP. Many recent efforts have used deep learning to either learn heuristics to solve or to directly solve the TSP.</p>
                        <br>
                        <p>By investigating the latent space of these models, we hope to:</p>
                        <ul>
                            <li>Learn details about the model itself, such as debugging and training dynamics</li>
                            <li>Identify motifs that could be externally useful to understanding the TSP domain</li>
                            <li>Extract other learned attributes of TSP instances for transfer learning</li>
                        </ul>
                        
                        <!-- TSP Solver Section -->
                        <div id="tsp-solver">
                            <h2>TSP Solver</h2>
                            <div>
                                <div class="section-nav">
                                    <a href="#architecture">Architecture</a> | 
                                    <a href="#data">Data</a> | 
                                    <a href="#training-method">Training Method</a>
                                </div>
                                
                                <h4 id="architecture" class="section-content-header">Architecture</h4>
                                <div style='width: 120%; margin-left: -10%; text-align: center; margin-top: 2rem; margin-bottom: 2rem;'>
                                    <img src='architecture.png' alt='SAE Feature Analysis Architecture' style='width: 90%; max-width: none; height: auto; border: 0px solid #ddd; border-radius: 8px;'>
                                    <p style='font-style: italic; margin-top: 0.5rem;'>System architecture showing the flow from TSP instances through the policy network to SAE feature extraction and analysis.</p>
                                </div>
                                
                                <p>We use (RL4CO)'s implementation of (Kool et al.)'s Transformer Pointer Network, which performs next-node prediction to autoregressively construct TSP solutions. We focus on TSP instances with a fixed size of 100 nodes.</p>

                                <h4 id="data" class="section-content-header">Data</h4>
                                <p>
                                Our TSP policy is trained on instances drawn from a configurable distribution. As a default, nodes are drawn uniformly over the unit square, but we also run experiments with more structured distributions, such as clustered Gaussians, concentric shapes (for example, points on a circle), latitude-longitude pairs from real road-network waypoints, and other custom generators. For consistency, the model is only evaluated on instance drawn from the same distribution as the training data.
                                </p>
                                
                                <div style="width: 120%; margin-left: -10%; display: flex; gap: 1rem; justify-content: center; margin-top: 2rem; margin-bottom: 2rem;">
                                    <img src="uniform_distribution.png" alt="Data Distribution Example 1" style="width: calc(33.33% - 0.67rem); aspect-ratio: 1; border: 1px solid #ddd; border-radius: 8px; object-fit: cover;">
                                    <img src="clusters_distribution.png" alt="Data Distribution Example 2" style="width: calc(33.33% - 0.67rem); aspect-ratio: 1; border: 1px solid #ddd; border-radius: 8px; object-fit: cover;">
                                    <img src="fuzzy_circle_distribution.png" alt="Data Distribution Example 3" style="width: calc(33.33% - 0.67rem); aspect-ratio: 1; border: 1px solid #ddd; border-radius: 8px; object-fit: cover;">
                                </div>
                                
                                <p>
                                During training, we resample the instances every epoch. For most settings, we used 100,000 instances per epoch for 300 epochs, or 30M unique instances. Alongside the training instances, we freeze a separate validation environment that resamples the same instances at each validation step. We also solve those validation tours optimally with the Concorde solver, so that we can record our model's performance in terms of suboptimality throughout training.
                                </p>

                                
                                <h4 id="training-method" class="section-content-header">Training Method</h4>
                                <p>Due to the nature of the TSP, generating optimal solutions at scale for supervised learning is computationally intractable. Instead, we train our solver using reinforcement learning, following the work of (Joshi) allowing the model to learn directly from interaction with the environment rather than relying on supervised labels. Training is conducted using the REINFORCE algorithm with gradient clipping to ensure stable parameter updates. Specifically, we use the RL4CO library's PyTorch Lightning-based training framework, including their TSP environment implementation. The reward signal is the negative tour length, incentivizing the model to find shorter tours. Each training run begins with a warm-up phase consisting of 1,000 greedy rollouts, which helps initialize the baseline and stabilize early policy learning. Afterwards, node selection during rollouts is sampled from a temperature-controlled softmax distribution. Once REINFORCE produces gradeints, we update parameters with the Adam optimizer.</p>

                                <div style='text-align: center; margin: 2rem 0;'>
                                    <img src='animation_demo.gif' alt='Training Results Animation Demo' style='width: 80%; max-width: none; height: auto; border: 1px solid #ddd; border-radius: 8px;'>
                                    <p style='font-style: italic; margin-top: 0.5rem;'>As the model trains, the solution to a fixed instance noticeably straightens out.</p>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Sparse Autoencoder Section -->
                        <div id="sparse-autoencoder">
                            <h2>Sparse Autoencoder</h2>
                            <div>
                                <div class="section-nav">
                                    <a href="#interp-goal">Interpretability Goal</a> | 
                                    <a href="#sae-background">SAE Background</a> | 
                                    <a href="#sae-training">SAE Training Details</a>
                                </div>
                                
                                <h4 id="interp-goal" class="section-content-header">Interpretability Goal</h4>
                                <p>Understanding what the neural TSP solver has learned requires dissecting its latent space in a human-interpretable way.  We adopt the language of *A Mathematical Framework for Transformer Circuits* framework (Elhage et al., 2021). In this view, "features" are important directions in the model's latent space that behave like variables: each has a value (its activation) on every forward pass. "Circuits," on the other hand, are relationships between these features that behave like functions. We focus on finding "features." If we can reliably name such variables ("this node is on the convex hull" or "that node is this node's nearest neighbor," for exaple), we build a mechanistic narrative of *why* the policy selects one next node over another.</p>
                                
                                <h4 id="sae-background" class="section-content-header">SAE Background</h4>
                                <p>A common obstacle in interpreting neural networks is *polysemanticity,* a phenomenon where individual neurons encode multiple, almost orthogonal concepts (Olsson et al., 2022). In language models, for example, this would look like a neuron that fires for both French negations and HTML tags, confounding interpretation. A popular tool for "disentangling" the neurons is the Sparse Autoencoder (SAE), a secondary ML model trained on the activations of the model being interpreted. SAE's learn an *over-complete* and *sparse* representation of the activations.</p>
                                <div style='text-align: center; margin: 2rem 0;'>
                                    <img src='dictionary.png' alt='Figure demonstrating dictionary learning' style='width: 80%; max-width: none; height: auto; border: 0px solid #ddd; border-radius: 8px;'>
                                    <p style='font-style: italic; margin-top: 0.5rem;'>Given the data in n = 2 dimensions (left), learn an overcomplete (d > n), sparse (|{active}| < n) basis to represent the data.</p>
                                </div>
                                <p style="padding-top: 1rem;">The SAE architecture has 3 compponents: an encoder, an activation function, and a decoder. Its training objective, as an autoencoder, is to reconstruct the input after passing it through its encoder's latent space. As a compression task, autoencoders typically have a smaller-dimensional latent space than the input. The key difference with <em>Sparse Autoencoders</em> is that the latent space is higher-dimensional, with the additional sparsity constraint:</p>
                                <img src="SAE_diagram.png" alt="SAE Architecture" style="width: 110%; max-width: none; height: auto; border: 0px solid #ddd; border-radius: 8px; margin-left: -4%; padding: 1rem 0;">
                                <p>Mathematically, the SAE forward pass consists of three steps. Given a node embedding \(x \in \mathbb{R}^d\), the <em>encoder</em> first projects to the latent space: \[z = xW_{\text{enc}}^{\top} + b\] where \(W_{\text{enc}} \in \mathbb{R}^{n \times d}\) contains the learned feature directions and \(b \in \mathbb{R}^n\) is a bias vector. Next, the <em>sparsification</em> step applies top-\(k\) activation: \[z_{\text{sparse}} = \text{TopK}(z) = \text{ReLU}(z - \tau)\] where \(\tau\) is the \(k\)-th largest value in \(z\), effectively zeroing all but the \(k\) largest activations, creating the sparse bottleneck. Finally, the <em>decoder</em> reconstructs the input: \[\hat{x} = z_{\text{sparse}}^{\top} W_{\text{dec}} + b_{\text{dec}}\] where \(W_{\text{dec}} \in \mathbb{R}^{n \times d}\) maps the sparse latent representation back to the original space.</p>
                                <br>
                                <p>
                                    Because of the sparsity constraint, the discovered features are less likely to be polysemantic, and more interpretable to humans. SAEs have been used to find colors/texture features in vision models (cite), features related to specific concepts (https://transformer-circuits.pub/2024/scaling-monosemanticity/) in LLMs, protein motifs in DNA foundation models (https://www.goodfire.ai/blog/interpreting-evo-2), and anomaly detection in robots (https://arxiv.org/html/2504.11170v2) among others. To our knowledge, our work is the first to apply the same tool to neural OR solvers.
                                </p>

                                <h4 id="sae-training" class="section-content-header">SAE Training Details</h4>
                                <p>Recall that the model works by first embedding the graph, then autoregressively decoding the solution. To capture the richest version of the graph's embedding, we attach the SAE to the encoder output, at the residual stream. Our SAE follows OpenAI's top-k SAE recipe (Gao et al., 2024). At each forward pass we zero all but a token's top-activating 10 % of SAE neurons, giving us an effective L0 constraint while still enjoying gradient flow through the soft top-k mask. The key hyperparameters are:</p>
                                <ul>
                                    <li><em>expansion factor</em>: how many times larger is the SAE's embedding space than the residual stream?</li>
                                    <li><em>k ratio</em>: k-sparsity of the SAE features (0.1 → 10% of features active)</li>
                                    <li><em>l1 coefficient</em>: Strength of the l1 sparsity penalty applied to the SAE activations</li>
                                    </li>
                                </ul>

                                <p>We collect the SAE's training data by running inference on the TSP model for 100,000 instances, collecting the graph embedding for each one. Crucially, these instances were drawn from the same distribution as the TSP solver's training data. After hyperparameter tuning, the resulting dictionary reconstructs residual activations to near-perfectly, with increasing sparsity as training progressed. </p>
                                <br>
                            </div>
                        </div>
                        
                        <!-- Feature Analysis Section -->
                        <div id="feature-analysis">
                            <h2>Feature Analysis</h2>
                            <div>
                                <div class="section-nav">
                                    <a href="#feature-analysis-methodology">Feature Activation Mechanics</a> | 
                                    <a href="#feature-visualization">Visualising a Feature</a> | 
                                    <a href="#discussion">Discussion</a>
                                </div>
                                
                                <h4 id="feature-analysis-methodology" class="section-content-header">Feature Activation Mechanics</h4>
                                <p>After training the SAE to discover interpretable feature directions, we want to understand how each feature responds to different TSP instances. A "feature activation" is simply the activation value of a specific neuron (feature) in the SAE's latent space. For a given node embedding \(x\), we compute the SAE's sparse latent representation \(z_{\text{sparse}}\) using the encoder and top-\(k\) sparsification described above. The activation of feature \(i\) is then just \(z_{\text{sparse}}[i]\)—the \(i\)-th component of this sparse vector.</p>
                                
                                <p>Since each TSP instance contains multiple nodes, feature \(i\) produces a collection of activations \(\{z_{\text{sparse}}[j,i]\}_{j=1}^{N}\) across all \(N\) nodes. To summarize how strongly a feature responds to an entire instance, we compute the mean activation:</p>
                                \[\mu_i \;=\; \tfrac{1}{N}\sum_{j=1}^{N} z_{\text{sparse}}[j,i].\]
                                <p>This mean activation helps us sort and identify the most relevant features for different types of TSP instances.</p>

                                <h4 id="feature-visualization" class="section-content-header">Visualising a Feature</h4>
                                <p>To see what a feature is doing we overlay ten fresh 100-node instances from the same distribution in a single \(x\)-\(y\) plot. Each point's colour encodes the corresponding value of \(z_{\text{sparse}}[j,i]\) (dark = 0, bright = high activation), while marker shape distinguishes which of the ten instances the node belongs to. Because activations are node-wise, this composite heat-map lets us spot geometric or combinatorial regularities at a glance—e.g. gradients that track tour direction, clusters of high-activation nodes near dense regions, or symmetry patterns that correlate with particular edge layouts.</p>

                                <h4 id="discussion" class="section-content-header">Discussion</h4>
                                <p>For demonstration, we trained an SAE on a model trained on uniform disrtibutions. We found many recurring themes of among the features, shown below:</p>
                                
                                <table style="width: 120%; border-collapse: collapse; margin: 2rem 0; margin-left: -10%;">
                                    <thead>
                                        <tr style="background-color: #f5f5f5;">
                                            <th style="border: 1px solid #ddd; padding: 12px; text-align: left; font-weight: bold; width: 15%;">Feature Type</th>
                                            <th style="border: 1px solid #ddd; padding: 12px; text-align: center; width: 28.33%;">Example 1</th>
                                            <th style="border: 1px solid #ddd; padding: 12px; text-align: center; width: 28.33%;">Example 2</th>
                                            <th style="border: 1px solid #ddd; padding: 12px; text-align: center; width: 28.33%;">Example 3</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td style="border: 1px solid #ddd; padding: 12px; font-weight: bold; width: 15%;">"I'm on the edge"</td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/edge/1.png" alt="Edge Feature Example 1" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/edge/2.png" alt="Edge Feature Example 2" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/edge/3.png" alt="Edge Feature Example 3" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                        </tr>
                                        <tr style="background-color: #fafafa;">
                                            <td style="border: 1px solid #ddd; padding: 12px; font-weight: bold; width: 15%;">"Focus on one spot"</td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/spot/1.png" alt="Focus Feature Example 1" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/spot/2.png" alt="Focus Feature Example 2" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/spot/3.png" alt="Focus Feature Example 3" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                        </tr>
                                        <tr>
                                            <td style="border: 1px solid #ddd; padding: 12px; font-weight: bold; width: 15%;">"Linear separator"</td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/linear/1.png" alt="Linear Feature Example 1" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/linear/2.png" alt="Linear Feature Example 2" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/linear/3.png" alt="Linear Feature Example 3" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                        </tr>
                                        <tr style="background-color: #fafafa;">
                                            <td style="border: 1px solid #ddd; padding: 12px; font-weight: bold; width: 15%;">Unclear / Mysterious</td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/other/1.png" alt="Other Feature Example 1" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/other/2.png" alt="Other Feature Example 2" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                            <td style="border: 1px solid #ddd; padding: 8px; text-align: center; width: 28.33%;">
                                                <img src="demo_overlays/other/3.png" alt="Other Feature Example 3" style="width: 100%; height: auto; object-fit: cover;">
                                            </td>
                                        </tr>
                                    </tbody>
                                </table>
                                
                                <p>These feature categories suggest that the SAE successfully disentangles different aspects of spatial reasoning that are important for TSP solving, from boundary detection to spatial clustering and geometric separations.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div id="demo-content" class="tab-content">
                <div class="feature-viewer">
                    <div class="feature-info">
                        <div class="info-row">
                            <div class="info-left">
                                <select id="feature-select" class="feature-title-select">
                                    <option value="409">Feature 409</option>
                                    <option value="941">Feature 941</option>
                                    <option value="894">Feature 894</option>
                                    <option value="227">Feature 227</option>
                                    <option value="945">Feature 945</option>
                                    <option value="1022">Feature 1022</option>
                                    <option value="348">Feature 348</option>
                                    <option value="874">Feature 874</option>
                                    <option value="762">Feature 762</option>
                                    <option value="764">Feature 764</option>
                                    <option value="239">Feature 239</option>
                                    <option value="951">Feature 951</option>
                                    <option value="374">Feature 374</option>
                                    <option value="898">Feature 898</option>
                                    <option value="50">Feature 50</option>
                                    <option value="323">Feature 323</option>
                                    <option value="82">Feature 82</option>
                                    <option value="948">Feature 948</option>
                                    <option value="978">Feature 978</option>
                                    <option value="272">Feature 272</option>
                                    <option value="770">Feature 770</option>
                                    <option value="555">Feature 555</option>
                                    <option value="730">Feature 730</option>
                                    <option value="329">Feature 329</option>
                                    <option value="689">Feature 689</option>
                                    <option value="287">Feature 287</option>
                                    <option value="310">Feature 310</option>
                                    <option value="243">Feature 243</option>
                                    <option value="710">Feature 710</option>
                                    <option value="63">Feature 63</option>
                                    <option value="596">Feature 596</option>
                                    <option value="76">Feature 76</option>
                                    <option value="501">Feature 501</option>
                                    <option value="787">Feature 787</option>
                                    <option value="210">Feature 210</option>
                                    <option value="829">Feature 829</option>
                                    <option value="836">Feature 836</option>
                                    <option value="616">Feature 616</option>
                                    <option value="376">Feature 376</option>
                                    <option value="443">Feature 443</option>
                                </select>
                            </div>
                            <div class="info-right">
                                <span class="config-label">Policy Config:</span> lr: 1e-05, epochs: 1000, embed_dim: 256, layers: 5, dropout: 0.1, temp: 1.0
                            </div>
                        </div>
                        <div class="info-row">
                            <div class="info-left">
                                <p><strong>Average Activation:</strong> <span id="current-activation">1.4363</span></p>
                            </div>
                            <div class="info-right">
                                <span class="config-label">SAE Config:</span> lr: 0.001, epochs: 30, exp_factor: 4.0, k_ratio: 0.1, l1_coef: 0.001, batch_size: 64
                            </div>
                        </div>
                    </div>
                    
                    <div class="feature-overlay-container">
                        <img id="current-overlay" 
                             src="feature_overlays/feature_409_overlay.png"
                             alt="Feature Overlay" 
                             class="feature-overlay"
                             onclick="openImage('feature_overlays/feature_409_overlay.png')">
                    </div>
                    
                    <h3>Top Activating Instances</h3>
                    <div class="instances-grid" id="top-instances-grid">
                        <!-- Top instances will be populated by JavaScript -->
                    </div>
                    
                    <h3>Bottom Activating Instances</h3>
                    <div class="instances-grid" id="bottom-instances-grid">
                        <!-- Bottom instances will be populated by JavaScript -->
                    </div>
                </div>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 TSP Solver Mechanistic Interpretability</p>
        </div>
    </footer>

    <script src="assets/js/main.js"></script>
</body>
</html> 